<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html>
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<title>Getting Started with healthcareai • healthcareai</title>
<!-- jquery --><script src="https://code.jquery.com/jquery-3.1.0.min.js" integrity="sha384-nrOSfDHtoPMzJHjVTdCopGqIqeYETSXhZDFyniQ8ZHcVy08QesyHcnOUpMpqnmWq" crossorigin="anonymous"></script><!-- Bootstrap --><link href="https://maxcdn.bootstrapcdn.com/bootswatch/3.3.7/yeti/bootstrap.min.css" rel="stylesheet" crossorigin="anonymous">
<script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/js/bootstrap.min.js" integrity="sha384-Tc5IQib027qvyjSMfHjOMaLkfuWVxZxUPnCJA7l2mCWNIpG9mGCD8wGNIcPD7Txa" crossorigin="anonymous"></script><!-- Font Awesome icons --><link href="https://maxcdn.bootstrapcdn.com/font-awesome/4.6.3/css/font-awesome.min.css" rel="stylesheet" integrity="sha384-T8Gy5hrqNKT+hzMclPo118YTQO6cYprQmhrYwIiQ/3axmI1hQomh7Ud2hPOy8SP1" crossorigin="anonymous">
<!-- clipboard.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/1.7.1/clipboard.min.js" integrity="sha384-cV+rhyOuRHc9Ub/91rihWcGmMmCXDeksTtCihMupQHSsi8GIIRDG0ThDc3HGQFJ3" crossorigin="anonymous"></script><!-- sticky kit --><script src="https://cdnjs.cloudflare.com/ajax/libs/sticky-kit/1.1.3/sticky-kit.min.js" integrity="sha256-c4Rlo1ZozqTPE2RLuvbusY3+SU1pQaJC0TjuhygMipw=" crossorigin="anonymous"></script><!-- pkgdown --><link href="../../pkgdown.css" rel="stylesheet">
<script src="../../pkgdown.js"></script><!-- docsearch --><script src="../../docsearch.js"></script><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/docsearch.js@2/dist/cdn/docsearch.min.css">
<link href="../../docsearch.css" rel="stylesheet">
<script src="https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/jquery.mark.min.js" integrity="sha256-4HLtjeVgH0eIB3aZ9mLYF6E8oU5chNdjU6p6rrXpl9U=" crossorigin="anonymous"></script><meta property="og:title" content="Getting Started with healthcareai">
<meta property="og:description" content="">
<meta property="og:image" content="https://docs.healthcare.ai/logo.png">
<meta name="twitter:card" content="summary">
<!-- mathjax --><script src="https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script><!--[if lt IE 9]>
<script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
<script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
<![endif]--><!-- Global site tag (gtag.js) - Google Analytics --><script async src="https://www.googletagmanager.com/gtag/js?id=UA-85609357-1"></script><script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-85609357-1');
</script>
</head>
<body>
    <div class="container template-article">
      <header><div class="navbar navbar-default navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <span class="navbar-brand">
        <a class="navbar-link" href="../../index.html">healthcareai</a>
        <span class="label label-default" data-toggle="tooltip" data-placement="bottom" title="Released package">2.2.0</span>
      </span>
    </div>

    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    Vignettes
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
<li>
      <a href="../../articles/site_only/healthcareai.html">Getting Started</a>
    </li>
    <li>
      <a href="../../articles/site_only/db_connections.html">Database Connections</a>
    </li>
    <li>
      <a href="../../articles/site_only/deploy_model.html">Deploying a Model</a>
    </li>
    <li>
      <a href="../../articles/site_only/best_levels.html">Variables with Many Categories</a>
    </li>
    <li>
      <a href="../../articles/site_only/performance.html">Performance with Big Data</a>
    </li>
    <li>
      <a href="../../articles/site_only/transitioning.html">Transition from Version 1</a>
    </li>
  </ul>
</li>
<li>
  <a href="../../reference/index.html">Functions</a>
</li>
<li>
  <a href="../../news/index.html">News</a>
</li>
      </ul>
<ul class="nav navbar-nav navbar-right">
<li>
  <a href="https://github.com/HealthCatalyst/healthcareai-r">
    <span class="fa fa-github"></span>
     
  </a>
</li>
<li>
  <a href="https://healthcare-ai.slack.com/">
    <span class="fa fa-users"></span>
     
  </a>
</li>
      </ul>
<form class="navbar-form navbar-right" role="search">
        <div class="form-group">
          <input type="search" class="form-control" name="search-input" id="search-input" placeholder="Search..." aria-label="Search for..." autocomplete="off">
</div>
      </form>
      
    </div>
<!--/.nav-collapse -->
  </div>
<!--/.container -->
</div>
<!--/.navbar -->

      
      </header><div class="row">
  <div class="col-md-9 contents">
    <div class="page-header toc-ignore">
      <h1>Getting Started with healthcareai</h1>
            
      
      
      <div class="hidden name"><code>healthcareai.Rmd</code></div>

    </div>

    
    
<p>First we attach the healthcareai R package to make its functions available. If your package version is less than 2.0, none of the code here will work. You can check the package version with <code>packageVersion("healthcareai")</code>, and you can get the latest stable version by running <code>install.packages("healthcareai")</code>. If you have v1.X code that you want to use with the new version of the package, check out the <a href="transitioning.html">Transitioning vignette</a>.</p>
<div class="sourceCode" id="cb1"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1-1" data-line-number="1"><span class="kw">library</span>(healthcareai)</a>
<a class="sourceLine" id="cb1-2" data-line-number="2"><span class="co"># &gt; healthcareai version 2.2.0</span></a>
<a class="sourceLine" id="cb1-3" data-line-number="3"><span class="co"># &gt; Please visit https://docs.healthcare.ai for full documentation and vignettes. Join the community at https://healthcare-ai.slack.com</span></a></code></pre></div>
<p><code>healthcareai</code> comes with a built in dataset documenting diabetes among adult Pima females. Once you attach the package, the dataset is available in the variable <code>pima_diabetes</code>. Let’s take a look at the data with the <code>str</code> function. There are 768 records in 10 variables including one identifier column, several nominal variables, and substantial missingness (represented in R by <code>NA</code>).</p>
<div class="sourceCode" id="cb2"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb2-1" data-line-number="1"><span class="kw">str</span>(pima_diabetes)</a>
<a class="sourceLine" id="cb2-2" data-line-number="2"><span class="co"># &gt; Classes 'tbl_df', 'tbl' and 'data.frame':   768 obs. of  10 variables:</span></a>
<a class="sourceLine" id="cb2-3" data-line-number="3"><span class="co"># &gt;  $ patient_id    : int  1 2 3 4 5 6 7 8 9 10 ...</span></a>
<a class="sourceLine" id="cb2-4" data-line-number="4"><span class="co"># &gt;  $ pregnancies   : int  6 1 8 1 0 5 3 10 2 8 ...</span></a>
<a class="sourceLine" id="cb2-5" data-line-number="5"><span class="co"># &gt;  $ plasma_glucose: int  148 85 183 89 137 116 78 115 197 125 ...</span></a>
<a class="sourceLine" id="cb2-6" data-line-number="6"><span class="co"># &gt;  $ diastolic_bp  : int  72 66 64 66 40 74 50 NA 70 96 ...</span></a>
<a class="sourceLine" id="cb2-7" data-line-number="7"><span class="co"># &gt;  $ skinfold      : int  35 29 NA 23 35 NA 32 NA 45 NA ...</span></a>
<a class="sourceLine" id="cb2-8" data-line-number="8"><span class="co"># &gt;  $ insulin       : int  NA NA NA 94 168 NA 88 NA 543 NA ...</span></a>
<a class="sourceLine" id="cb2-9" data-line-number="9"><span class="co"># &gt;  $ weight_class  : chr  "obese" "overweight" "normal" "overweight" ...</span></a>
<a class="sourceLine" id="cb2-10" data-line-number="10"><span class="co"># &gt;  $ pedigree      : num  0.627 0.351 0.672 0.167 2.288 ...</span></a>
<a class="sourceLine" id="cb2-11" data-line-number="11"><span class="co"># &gt;  $ age           : int  50 31 32 21 33 30 26 29 53 54 ...</span></a>
<a class="sourceLine" id="cb2-12" data-line-number="12"><span class="co"># &gt;  $ diabetes      : chr  "Y" "N" "Y" "N" ...</span></a></code></pre></div>
<div id="easy-machine-learning" class="section level1">
<h1 class="hasAnchor">
<a href="#easy-machine-learning" class="anchor"></a>Easy Machine Learning</h1>
<p>If you don’t want to fuss with details any more than necessary, <code>machine_learn</code> is the function for you. It makes it as easy as possible to implement machine learning models by putting all the detains in the background so that you don’t have to worry about them. Of course it might be wise to worry about them, and we’ll get to how to do that further down, but for now, you can automatically take care of problems in the data, do basic feature engineering, and tune multiple machine learning models using cross validation with <code>machine_learn</code>.</p>
<p><code>machine_learn</code> always gets the name of the data frame, then any columns that should not be used by the model (uninformative columns, such as IDs), then the variable to be predicted with <code>outcome =</code>. If you want <code>machine_learn</code> to run faster, you can have that—at the expense of a bit of predictive power—by setting its <code>tune</code> argument to <code>FALSE</code>.</p>
<div class="sourceCode" id="cb3"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb3-1" data-line-number="1">quick_models &lt;-<span class="st"> </span><span class="kw"><a href="../../reference/machine_learn.html">machine_learn</a></span>(pima_diabetes, patient_id, <span class="dt">outcome =</span> diabetes)</a>
<a class="sourceLine" id="cb3-2" data-line-number="2"><span class="co"># &gt; Training new data prep recipe...</span></a>
<a class="sourceLine" id="cb3-3" data-line-number="3"><span class="co"># &gt; Variable(s) ignored in prep_data won't be used to tune models: patient_id</span></a>
<a class="sourceLine" id="cb3-4" data-line-number="4"><span class="co"># &gt; </span></a>
<a class="sourceLine" id="cb3-5" data-line-number="5"><span class="co"># &gt; diabetes looks categorical, so training classification algorithms.</span></a>
<a class="sourceLine" id="cb3-6" data-line-number="6"><span class="co"># &gt; </span></a>
<a class="sourceLine" id="cb3-7" data-line-number="7"><span class="co"># &gt; After data processing, models are being trained on 12 features with 768 observations.</span></a>
<a class="sourceLine" id="cb3-8" data-line-number="8"><span class="co"># &gt; Based on n_folds = 5 and hyperparameter settings, the following number of models will be trained: 50 rf's, 50 xgb's, and 100 glm's</span></a>
<a class="sourceLine" id="cb3-9" data-line-number="9"><span class="co"># &gt; Training with cross validation: Random Forest</span></a>
<a class="sourceLine" id="cb3-10" data-line-number="10"><span class="co"># &gt; Training with cross validation: eXtreme Gradient Boosting</span></a>
<a class="sourceLine" id="cb3-11" data-line-number="11"><span class="co"># &gt; Training with cross validation: glmnet</span></a>
<a class="sourceLine" id="cb3-12" data-line-number="12"><span class="co"># &gt; </span></a>
<a class="sourceLine" id="cb3-13" data-line-number="13"><span class="co"># &gt; *** Models successfully trained. The model object contains the training data minus ignored ID columns. ***</span></a>
<a class="sourceLine" id="cb3-14" data-line-number="14"><span class="co"># &gt; *** If there was PHI in training data, normal PHI protocols apply to the model object. ***</span></a></code></pre></div>
<p><code>machine_learn</code> has told us that it has created a recipe for data preparation (this allows us to do exactly the same data cleaning and feature engineering when you want predictions on a new dataset), is ignoring <code>patient_id</code> when tuning models as we told it to, is training classification algorithms because the outcome variable <code>diabetes</code> is categorical, and has executed cross validation for three machine learning models: random forests, XGBoost, and regularized regression. Let’s see what the models look like.</p>
<div class="sourceCode" id="cb4"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb4-1" data-line-number="1">quick_models</a>
<a class="sourceLine" id="cb4-2" data-line-number="2"><span class="co"># &gt; Algorithms Trained: Random Forest, eXtreme Gradient Boosting, and glmnet</span></a>
<a class="sourceLine" id="cb4-3" data-line-number="3"><span class="co"># &gt; Model Name: diabetes</span></a>
<a class="sourceLine" id="cb4-4" data-line-number="4"><span class="co"># &gt; Target: diabetes</span></a>
<a class="sourceLine" id="cb4-5" data-line-number="5"><span class="co"># &gt; Class: Classification</span></a>
<a class="sourceLine" id="cb4-6" data-line-number="6"><span class="co"># &gt; Performance Metric: AUROC</span></a>
<a class="sourceLine" id="cb4-7" data-line-number="7"><span class="co"># &gt; Number of Observations: 768</span></a>
<a class="sourceLine" id="cb4-8" data-line-number="8"><span class="co"># &gt; Number of Features: 12</span></a>
<a class="sourceLine" id="cb4-9" data-line-number="9"><span class="co"># &gt; Models Trained: 2018-09-01 18:26:54 </span></a>
<a class="sourceLine" id="cb4-10" data-line-number="10"><span class="co"># &gt; </span></a>
<a class="sourceLine" id="cb4-11" data-line-number="11"><span class="co"># &gt; Models tuned via 5-fold cross validation over 10 combinations of hyperparameter values.</span></a>
<a class="sourceLine" id="cb4-12" data-line-number="12"><span class="co"># &gt; Best model: Random Forest</span></a>
<a class="sourceLine" id="cb4-13" data-line-number="13"><span class="co"># &gt; AUPR = 0.71, AUROC = 0.84</span></a>
<a class="sourceLine" id="cb4-14" data-line-number="14"><span class="co"># &gt; Optimal hyperparameter values:</span></a>
<a class="sourceLine" id="cb4-15" data-line-number="15"><span class="co"># &gt;   mtry = 9</span></a>
<a class="sourceLine" id="cb4-16" data-line-number="16"><span class="co"># &gt;   splitrule = extratrees</span></a>
<a class="sourceLine" id="cb4-17" data-line-number="17"><span class="co"># &gt;   min.node.size = 9</span></a></code></pre></div>
<p>Everything looks as expected, and the best model is is a random forest that achieves performance of AUROC = 0.84. Not bad for one line of code.</p>
<p>Now that we have our models, we can make predictions using the <code>predict</code> function. If you provide a new data frame to <code>predict</code> it will make predictions on the new data; otherwise, it will make predictions on the training data.</p>
<div class="sourceCode" id="cb5"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb5-1" data-line-number="1">predictions &lt;-<span class="st"> </span><span class="kw">predict</span>(quick_models)</a>
<a class="sourceLine" id="cb5-2" data-line-number="2">predictions</a>
<a class="sourceLine" id="cb5-3" data-line-number="3"><span class="co"># &gt; "predicted_diabetes" predicted by Random Forest last trained: 2018-09-01 18:26:54</span></a>
<a class="sourceLine" id="cb5-4" data-line-number="4"><span class="co"># &gt; Performance in training: AUROC = 0.84</span></a>
<a class="sourceLine" id="cb5-5" data-line-number="5"><span class="co"># &gt; # A tibble: 768 x 11</span></a>
<a class="sourceLine" id="cb5-6" data-line-number="6"><span class="co"># &gt;   diabetes predicted_diabe… patient_id pregnancies plasma_glucose</span></a>
<a class="sourceLine" id="cb5-7" data-line-number="7"><span class="co"># &gt; * &lt;fct&gt;               &lt;dbl&gt;      &lt;int&gt;       &lt;int&gt;          &lt;int&gt;</span></a>
<a class="sourceLine" id="cb5-8" data-line-number="8"><span class="co"># &gt; 1 Y                 0.765            1           6            148</span></a>
<a class="sourceLine" id="cb5-9" data-line-number="9"><span class="co"># &gt; 2 N                 0.0506           2           1             85</span></a>
<a class="sourceLine" id="cb5-10" data-line-number="10"><span class="co"># &gt; 3 Y                 0.518            3           8            183</span></a>
<a class="sourceLine" id="cb5-11" data-line-number="11"><span class="co"># &gt; 4 N                 0.00349          4           1             89</span></a>
<a class="sourceLine" id="cb5-12" data-line-number="12"><span class="co"># &gt; 5 Y                 0.637            5           0            137</span></a>
<a class="sourceLine" id="cb5-13" data-line-number="13"><span class="co"># &gt; # ... with 763 more rows, and 6 more variables: diastolic_bp &lt;int&gt;,</span></a>
<a class="sourceLine" id="cb5-14" data-line-number="14"><span class="co"># &gt; #   skinfold &lt;int&gt;, insulin &lt;int&gt;, weight_class &lt;chr&gt;, pedigree &lt;dbl&gt;,</span></a>
<a class="sourceLine" id="cb5-15" data-line-number="15"><span class="co"># &gt; #   age &lt;int&gt;</span></a></code></pre></div>
<p>We get a message about when the model was trained and how well it preformed in training, and we get back a data frame that looks sort of like the original, but has a new column <code>predited_diabetes</code> that contains the model-generated probability each individual has diabetes, and contains changes that were made preparing the data for model training, e.g. missingness has been filled in and <code>weight_class</code> has been split into a series of “dummy” variables.</p>
<p>We can plot how effectively the model is able to separate diabetic from non-diabetic individuals by calling the <code>plot</code> function on the output of <code>predict</code>.</p>
<div class="sourceCode" id="cb6"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb6-1" data-line-number="1"><span class="kw">plot</span>(predictions)</a></code></pre></div>
<p><img src="healthcareai_files/figure-html/unnamed-chunk-6-1.png" width="576"></p>
<p>If you want outcome-class predictions in addition to predicted probabilites, the <code>outcome_groups</code> argument accomplishes that. If it is <code>TRUE</code> the overall accuracy of predictions is maximized. If it is a number, it represents the relative cost of a false-negative to a false-positive outcome. The example below says that one false negative is as bad as two false positives. If you want risk groups instead, see the <code>risk_groups</code> argument.</p>
<div class="sourceCode" id="cb7"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb7-1" data-line-number="1">quick_models <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb7-2" data-line-number="2"><span class="st">  </span><span class="kw">predict</span>(<span class="dt">outcome_groups =</span> <span class="dv">2</span>) <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb7-3" data-line-number="3"><span class="st">  </span><span class="kw">plot</span>()</a></code></pre></div>
<p><img src="healthcareai_files/figure-html/unnamed-chunk-7-1.png" width="576"></p>
</div>
<div id="data-profiling" class="section level1">
<h1 class="hasAnchor">
<a href="#data-profiling" class="anchor"></a>Data Profiling</h1>
<p>It is always a good idea to be aware of where there are missing values in data. The <code>missingness</code> function helps with that. In addition to looking for values R sees as missing, it looks for other values that might represent missing, such as <code>"NULL"</code>, and issues a warning if it finds any. Like many <code>healthcareai</code> functions, it has a <code>plot</code> method so you can inspect the results more quickly and intuitively by passing the output to <code>plot</code>.</p>
<div class="sourceCode" id="cb8"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb8-1" data-line-number="1"><span class="kw"><a href="../../reference/missingness.html">missingness</a></span>(pima_diabetes) <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb8-2" data-line-number="2"><span class="st">  </span><span class="kw">plot</span>()</a></code></pre></div>
<p><img src="healthcareai_files/figure-html/unnamed-chunk-8-1.png" width="576"></p>
<p>It’s good that we don’t have any missingness in our ID or outcome columns. We’ll see how missingness in predictors is addressed further down.</p>
</div>
<div id="data-preparation" class="section level1">
<h1 class="hasAnchor">
<a href="#data-preparation" class="anchor"></a>Data Preparation</h1>
<p>To get an honest picture of how well a model performs (and an accurate estimate of how well it will perform on yet-unseen data), it is wise to hide a small portion of observations from model training and assess model performance on this “validation” or “test” dataset. In fact, <code>healthcareai</code> does this automatically and repeatedly under the hood, so it’s not strictly necessary, but it’s still a good idea. The <code>split_train_test</code> function simplifies this, and it ensures the test dataset has proportionally similar characteristics to the training dataset. By default, 80% of observations are used for training; that proportion can be adjusted with the <code>p</code> parameter. The <code>seed</code> parameter controls randomness so that you can get the same split every time you run the code if you want strict reproducability.</p>
<div class="sourceCode" id="cb9"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb9-1" data-line-number="1">split_data &lt;-<span class="st"> </span><span class="kw"><a href="../../reference/split_train_test.html">split_train_test</a></span>(<span class="dt">d =</span> pima_diabetes,</a>
<a class="sourceLine" id="cb9-2" data-line-number="2">                               <span class="dt">outcome =</span> diabetes,</a>
<a class="sourceLine" id="cb9-3" data-line-number="3">                               <span class="dt">p =</span> <span class="fl">.9</span>,</a>
<a class="sourceLine" id="cb9-4" data-line-number="4">                               <span class="dt">seed =</span> <span class="dv">84105</span>)</a></code></pre></div>
<p><code>split_data</code> contains two data frames, named <code>train</code> and <code>test</code>.</p>
<p>One of the major workhorse functions in <code>healthcareai</code> is <code>prep_data</code>. It is called under-the-hood by <code>machine_learn</code>, so you don’t have to worry about these details if you don’t want to, but eventually you’ll want to customize how your data is prepared; this is where you do that. The helpfile <code><a href="../../reference/prep_data.html">?prep_data</a></code> describes what the function does and how it can be customized. Here, let’s customize preparation to scale and center numeric variables and avoid collapsing rare factor levels into “other”.</p>
<p>The first arguments to <code>prep_data</code> are the same as those to <code>machine_learn</code>: data frame, ignored columns, and the outcome column. Then we can specify prep details.</p>
<div class="sourceCode" id="cb10"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb10-1" data-line-number="1">prepped_training_data &lt;-<span class="st"> </span><span class="kw"><a href="../../reference/prep_data.html">prep_data</a></span>(split_data<span class="op">$</span>train, patient_id, <span class="dt">outcome =</span> diabetes,</a>
<a class="sourceLine" id="cb10-2" data-line-number="2">                                   <span class="dt">center =</span> <span class="ot">TRUE</span>, <span class="dt">scale =</span> <span class="ot">TRUE</span>,</a>
<a class="sourceLine" id="cb10-3" data-line-number="3">                                   <span class="dt">collapse_rare_factors =</span> <span class="ot">FALSE</span>)</a>
<a class="sourceLine" id="cb10-4" data-line-number="4"><span class="co"># &gt; Training new data prep recipe...</span></a></code></pre></div>
<p>The “recipe” that the above message refers to is a set of instructions for how to transform a dataset the way we just transformed our training data. Any machine learning that we do (within <code>healthcareai</code>) on <code>prepped_training_data</code> will retain that recipe and apply it before making predictions on new data. That means that when you have models making predictions in production, you don’t have to figure out how to transform the data or worry about encountering missing data or new category levels.</p>
</div>
<div id="model-training" class="section level1">
<h1 class="hasAnchor">
<a href="#model-training" class="anchor"></a>Model Training</h1>
<p><code>machine_learn</code> takes care of data preparation and model training for you, but if you want more precise control, <code>tune_models</code> and <code>flash_models</code> are the model-training function you’re looking for. They differ in that <code>tune_models</code> searches over hyperparameters to optimize model performance, while <code>flash_models</code> trains models at set hyperparameter values. So, <code>tune_models</code> produces better models, but takes longer (approaching 10x longer at default settings).</p>
<p>Let’s tune all three available models: random forests (“RF”), regularized regression (i.e. lasso and ridge, “GLM”), and gradient-boosted decision trees (i.e. XGBoost, “XGB”). To optimize model performance, let’s crank <code>tune_depth</code> up a little from its default value of ten. That will tune the models over more combinations of hyperparameter values in the search for the best model. This will increasing training time, so be cautious with it at first, but for this modest-sized dataset, the entire process takes less than a minute to complete on a laptop.</p>
<p>Let’s also select “PR” as our model metric. That optimizes for area under the precision-recall curve rather than the default of area under the receiver operating characteristic curve (“ROC”). This is usually a good idea when one outcome category is much more common than the other category.</p>
<div class="sourceCode" id="cb11"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb11-1" data-line-number="1">models &lt;-<span class="st"> </span><span class="kw"><a href="../../reference/tune_models.html">tune_models</a></span>(<span class="dt">d =</span> prepped_training_data,</a>
<a class="sourceLine" id="cb11-2" data-line-number="2">                      <span class="dt">outcome =</span> diabetes,</a>
<a class="sourceLine" id="cb11-3" data-line-number="3">                      <span class="dt">tune_depth =</span> <span class="dv">25</span>,</a>
<a class="sourceLine" id="cb11-4" data-line-number="4">                      <span class="dt">metric =</span> <span class="st">"PR"</span>)</a>
<a class="sourceLine" id="cb11-5" data-line-number="5"><span class="co"># &gt; Variable(s) ignored in prep_data won't be used to tune models: patient_id</span></a>
<a class="sourceLine" id="cb11-6" data-line-number="6"><span class="co"># &gt; </span></a>
<a class="sourceLine" id="cb11-7" data-line-number="7"><span class="co"># &gt; diabetes looks categorical, so training classification algorithms.</span></a>
<a class="sourceLine" id="cb11-8" data-line-number="8"><span class="co"># &gt; </span></a>
<a class="sourceLine" id="cb11-9" data-line-number="9"><span class="co"># &gt; After data processing, models are being trained on 13 features with 692 observations.</span></a>
<a class="sourceLine" id="cb11-10" data-line-number="10"><span class="co"># &gt; Based on n_folds = 5 and hyperparameter settings, the following number of models will be trained: 125 rf's, 125 xgb's, and 250 glm's</span></a>
<a class="sourceLine" id="cb11-11" data-line-number="11"><span class="co"># &gt; Training with cross validation: Random Forest</span></a>
<a class="sourceLine" id="cb11-12" data-line-number="12"><span class="co"># &gt; Training with cross validation: eXtreme Gradient Boosting</span></a>
<a class="sourceLine" id="cb11-13" data-line-number="13"><span class="co"># &gt; Training with cross validation: glmnet</span></a>
<a class="sourceLine" id="cb11-14" data-line-number="14"><span class="co"># &gt; </span></a>
<a class="sourceLine" id="cb11-15" data-line-number="15"><span class="co"># &gt; *** Models successfully trained. The model object contains the training data minus ignored ID columns. ***</span></a>
<a class="sourceLine" id="cb11-16" data-line-number="16"><span class="co"># &gt; *** If there was PHI in training data, normal PHI protocols apply to the model object. ***</span></a></code></pre></div>
<p>You can compare performance across models with <code>evaluate</code>.</p>
<div class="sourceCode" id="cb12"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb12-1" data-line-number="1"><span class="kw"><a href="../../reference/evaluate.html">evaluate</a></span>(models, <span class="dt">all_models =</span> <span class="ot">TRUE</span>)</a>
<a class="sourceLine" id="cb12-2" data-line-number="2"><span class="co"># &gt; # A tibble: 3 x 3</span></a>
<a class="sourceLine" id="cb12-3" data-line-number="3"><span class="co"># &gt;   model                      AUPR AUROC</span></a>
<a class="sourceLine" id="cb12-4" data-line-number="4"><span class="co"># &gt;   &lt;chr&gt;                     &lt;dbl&gt; &lt;dbl&gt;</span></a>
<a class="sourceLine" id="cb12-5" data-line-number="5"><span class="co"># &gt; 1 Random Forest             0.715 0.841</span></a>
<a class="sourceLine" id="cb12-6" data-line-number="6"><span class="co"># &gt; 2 eXtreme Gradient Boosting 0.711 0.827</span></a>
<a class="sourceLine" id="cb12-7" data-line-number="7"><span class="co"># &gt; 3 glmnet                    0.697 0.823</span></a></code></pre></div>
<p>For more detail, you can examine how models perform across hyperparameters by plotting the model object. Here we plot only the best model’s performance over hyperparameter by extracting it by name. It looks like extratrees is a superior split rule for this model.</p>
<div class="sourceCode" id="cb13"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb13-1" data-line-number="1">models[<span class="st">"Random Forest"</span>] <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb13-2" data-line-number="2"><span class="st">  </span><span class="kw">plot</span>()</a></code></pre></div>
<p><img src="healthcareai_files/figure-html/unnamed-chunk-13-1.png" width="864"></p>
<div id="faster-model-training" class="section level2">
<h2 class="hasAnchor">
<a href="#faster-model-training" class="anchor"></a>Faster Model Training</h2>
<p>If you’re feeling the need for speed, <code>flash_models</code> is the function for you. It uses fixed sets of hyperparameter values to train the models, so you still get a model customized to your data, but without burning the electricity and time to precisely optimize all the details. Here we’ll use <code>models = "RF"</code> to train only a random forest.</p>
<p>If you want to train a model on fixed hyperparameter values, but you want to choose those values, you can pass them to the <code>hyperparameters</code> argument of <code>tune_models</code>. Run <code><a href="../../reference/get_hyperparameter_defaults.html">get_hyperparameter_defaults()</a></code> to see the default values and get a list you can customize.</p>
<div class="sourceCode" id="cb14"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb14-1" data-line-number="1">untuned_rf &lt;-<span class="st"> </span><span class="kw"><a href="../../reference/flash_models.html">flash_models</a></span>(<span class="dt">d =</span> prepped_training_data,</a>
<a class="sourceLine" id="cb14-2" data-line-number="2">                           <span class="dt">outcome =</span> diabetes,</a>
<a class="sourceLine" id="cb14-3" data-line-number="3">                           <span class="dt">models =</span> <span class="st">"RF"</span>,</a>
<a class="sourceLine" id="cb14-4" data-line-number="4">                           <span class="dt">metric =</span> <span class="st">"PR"</span>)</a>
<a class="sourceLine" id="cb14-5" data-line-number="5"><span class="co"># &gt; Variable(s) ignored in prep_data won't be used to tune models: patient_id</span></a>
<a class="sourceLine" id="cb14-6" data-line-number="6"><span class="co"># &gt; </span></a>
<a class="sourceLine" id="cb14-7" data-line-number="7"><span class="co"># &gt; diabetes looks categorical, so training classification algorithms.</span></a>
<a class="sourceLine" id="cb14-8" data-line-number="8"><span class="co"># &gt; </span></a>
<a class="sourceLine" id="cb14-9" data-line-number="9"><span class="co"># &gt; After data processing, models are being trained on 13 features with 692 observations.</span></a>
<a class="sourceLine" id="cb14-10" data-line-number="10"><span class="co"># &gt; Based on n_folds = 5 and hyperparameter settings, the following number of models will be trained: 5 rf's</span></a>
<a class="sourceLine" id="cb14-11" data-line-number="11"><span class="co"># &gt; Training at fixed values: Random Forest</span></a>
<a class="sourceLine" id="cb14-12" data-line-number="12"><span class="co"># &gt; </span></a>
<a class="sourceLine" id="cb14-13" data-line-number="13"><span class="co"># &gt; *** Models successfully trained. The model object contains the training data minus ignored ID columns. ***</span></a>
<a class="sourceLine" id="cb14-14" data-line-number="14"><span class="co"># &gt; *** If there was PHI in training data, normal PHI protocols apply to the model object. ***</span></a></code></pre></div>
</div>
</div>
<div id="model-interpretation" class="section level1">
<h1 class="hasAnchor">
<a href="#model-interpretation" class="anchor"></a>Model Interpretation</h1>
<div id="interpret" class="section level2">
<h2 class="hasAnchor">
<a href="#interpret" class="anchor"></a>Interpret</h2>
<p>If you trained a GLM model, you can extract model coefficients from it with the <code>interpret</code> function. These are coefficient estimates from a regularized logistic or linear regression model. If you didn’t scale your predictors (which is the default in <code>prep_data</code>), these will be in natural units (e.g. in the plot below, a unit increase in plasma glucose corresponds to an expected log-odds increase of diabetes of just over one). Importantly, natural units mean that you can’t interpret the size of the coefficients as the importance of the predictor. To get that interpretation, scale your features during data preparation by calling <code>prep_data</code> with <code>scale = TRUE</code> and then <code>flash_models</code> or <code>tune_models</code>.</p>
<p>In this plot, the low value of <code>weight_class_normal</code> signifies that people with normal weight are less likely to have diabetes. Similarly, plasma glucose is associated with increased risk of diabetes after accounting for other variables.</p>
<div class="sourceCode" id="cb15"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb15-1" data-line-number="1"><span class="kw"><a href="../../reference/interpret.html">interpret</a></span>(models) <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb15-2" data-line-number="2"><span class="st">  </span><span class="kw">plot</span>()</a>
<a class="sourceLine" id="cb15-3" data-line-number="3"><span class="co"># &gt; Warning in interpret(models): Interpreting glmnet model, but Random Forest</span></a>
<a class="sourceLine" id="cb15-4" data-line-number="4"><span class="co"># &gt; performed best in cross-validation and will be used to make predictions. To</span></a>
<a class="sourceLine" id="cb15-5" data-line-number="5"><span class="co"># &gt; use the glmnet model for predictions, extract it with x['glmnet'].</span></a></code></pre></div>
<p><img src="healthcareai_files/figure-html/unnamed-chunk-15-1.png" width="672"></p>
</div>
<div id="variable-importance" class="section level2">
<h2 class="hasAnchor">
<a href="#variable-importance" class="anchor"></a>Variable Importance</h2>
<p>Tree based methods such as random forest and boosted decision trees can’t provide coefficients like regularized regression models can, but they can provide information about how important each feature (aka predictor, aka variable) is for making accurate predictions. You can see these “variable importances” by calling <code>get_variable_importance</code> on your model object. Like <code>interpret</code> and many other functions in <code>healthcareai</code>, you can plot the output of <code>get_variable_importance</code> with a simple <code>plot</code> call.</p>
<div class="sourceCode" id="cb16"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb16-1" data-line-number="1"><span class="kw"><a href="../../reference/get_variable_importance.html">get_variable_importance</a></span>(models) <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb16-2" data-line-number="2"><span class="st">  </span><span class="kw">plot</span>()</a></code></pre></div>
<p><img src="healthcareai_files/figure-html/unnamed-chunk-16-1.png" width="672"></p>
</div>
<div id="explore" class="section level2">
<h2 class="hasAnchor">
<a href="#explore" class="anchor"></a>Explore</h2>
<p>The <code>explore</code> function reveals how a model makes its predictions. It takes the most important features in a model, and uses a variety of “counterfactual” observations across those features to see what predictions the model would make at various combinations of the features. To see the effect of more features adjust the <code>n_use</code> argument to <code>plot</code>, or for different features, specify <code>x_var</code> and <code>color_var</code>.</p>
<div class="sourceCode" id="cb17"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb17-1" data-line-number="1"><span class="kw"><a href="../../reference/explore.html">explore</a></span>(models) <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb17-2" data-line-number="2"><span class="st">  </span><span class="kw">plot</span>()</a>
<a class="sourceLine" id="cb17-3" data-line-number="3"><span class="co"># &gt; With 4 varying features and n_use = 2, using median to aggregate predicted outcomes across age and pregnancies. You could turn `n_use` up to see the impact of more features.</span></a></code></pre></div>
<p><img src="healthcareai_files/figure-html/unnamed-chunk-17-1.png" width="576"></p>
</div>
</div>
<div id="prediction" class="section level1">
<h1 class="hasAnchor">
<a href="#prediction" class="anchor"></a>Prediction</h1>
<p><code>predict</code> will automatically use the best-performing model from training (evaluated out-of-fold in cross validation). If no new data is passed to <code>predict</code> it will return out-of-fold predictions from training. The predicted probabilities appear in the <code>predicted_diabetes</code> column.</p>
<div class="sourceCode" id="cb18"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb18-1" data-line-number="1"><span class="kw">predict</span>(models)</a>
<a class="sourceLine" id="cb18-2" data-line-number="2"><span class="co"># &gt; "predicted_diabetes" predicted by Random Forest last trained: 2018-09-01 18:27:33</span></a>
<a class="sourceLine" id="cb18-3" data-line-number="3"><span class="co"># &gt; Performance in training: AUPR = 0.71</span></a>
<a class="sourceLine" id="cb18-4" data-line-number="4"><span class="co"># &gt; # A tibble: 692 x 11</span></a>
<a class="sourceLine" id="cb18-5" data-line-number="5"><span class="co"># &gt;   diabetes predicted_diabe… patient_id pregnancies plasma_glucose</span></a>
<a class="sourceLine" id="cb18-6" data-line-number="6"><span class="co"># &gt; * &lt;fct&gt;               &lt;dbl&gt;      &lt;int&gt;       &lt;int&gt;          &lt;int&gt;</span></a>
<a class="sourceLine" id="cb18-7" data-line-number="7"><span class="co"># &gt; 1 N                  0.0874          2           1             85</span></a>
<a class="sourceLine" id="cb18-8" data-line-number="8"><span class="co"># &gt; 2 Y                  0.409           3           8            183</span></a>
<a class="sourceLine" id="cb18-9" data-line-number="9"><span class="co"># &gt; 3 N                  0.0134          4           1             89</span></a>
<a class="sourceLine" id="cb18-10" data-line-number="10"><span class="co"># &gt; 4 Y                  0.559           5           0            137</span></a>
<a class="sourceLine" id="cb18-11" data-line-number="11"><span class="co"># &gt; 5 N                  0.202           6           5            116</span></a>
<a class="sourceLine" id="cb18-12" data-line-number="12"><span class="co"># &gt; # ... with 687 more rows, and 6 more variables: diastolic_bp &lt;int&gt;,</span></a>
<a class="sourceLine" id="cb18-13" data-line-number="13"><span class="co"># &gt; #   skinfold &lt;int&gt;, insulin &lt;int&gt;, weight_class &lt;chr&gt;, pedigree &lt;dbl&gt;,</span></a>
<a class="sourceLine" id="cb18-14" data-line-number="14"><span class="co"># &gt; #   age &lt;int&gt;</span></a></code></pre></div>
<p>To get predictions on a new dataset, pass the new data to <code>predict</code>, and it will automatically be prepared based on the recipe generated on the training data. We can plot the predictions to see how well our model is doing, and we see that it’s separating diabetic from non-diabetic individuals pretty well, although there a fair number of non-diabetics with high predicted probabilities of diabetes. This may be due to optimizing for precision recall, or may indicate pre-diabetic patients.</p>
<p>Above, we saw how to make outcome-class predictions. Here, we make risk-group predictions, defining four risk groups (low, moderate, high, and extreme) containing 30%, 40%, 20% and 10% of patients, respectively.</p>
<div class="sourceCode" id="cb19"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb19-1" data-line-number="1">test_predictions &lt;-<span class="st"> </span></a>
<a class="sourceLine" id="cb19-2" data-line-number="2"><span class="st">  </span><span class="kw">predict</span>(models, </a>
<a class="sourceLine" id="cb19-3" data-line-number="3">          split_data<span class="op">$</span>test, </a>
<a class="sourceLine" id="cb19-4" data-line-number="4">          <span class="dt">risk_groups =</span> <span class="kw">c</span>(<span class="dt">low =</span> <span class="dv">30</span>, <span class="dt">moderate =</span> <span class="dv">40</span>, <span class="dt">high =</span> <span class="dv">20</span>, <span class="dt">extreme =</span> <span class="dv">10</span>)</a>
<a class="sourceLine" id="cb19-5" data-line-number="5">  )</a>
<a class="sourceLine" id="cb19-6" data-line-number="6"><span class="co"># &gt; Prepping data based on provided recipe</span></a>
<a class="sourceLine" id="cb19-7" data-line-number="7"><span class="kw">plot</span>(test_predictions)</a></code></pre></div>
<p><img src="healthcareai_files/figure-html/unnamed-chunk-19-1.png" width="576"></p>
</div>
<div id="saving-moving-and-loading-models" class="section level1">
<h1 class="hasAnchor">
<a href="#saving-moving-and-loading-models" class="anchor"></a>Saving, Moving, and Loading Models</h1>
<p>Everything we have done above happens “in memory”. It’s all within one R session, so there’s no need to save anything to disk or load anything back into R. Putting a machine learning model in production typically means moving the model into a production environment. To do that, save the model with <code>save_models</code> function.</p>
<div class="sourceCode" id="cb20"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb20-1" data-line-number="1"><span class="kw"><a href="../../reference/save_models.html">save_models</a></span>(models, <span class="dt">file =</span> <span class="st">"my_models.RDS"</span>)</a></code></pre></div>
<p>The above code will store the <code>models</code> object with all its metadata in the <code>my_models.RDS</code> file in the working directory, which you can identify with <code>getwd()</code>. You can move that file to any other directory or machine, even across operating systems, and pull it back into R with the <code>load_models</code> function.</p>
<p>The only tricky thing here is you have to direct <code>load_models</code> to the directory that the model file is in. If you don’t provide a filepath, i.e. call <code><a href="../../reference/save_models.html">load_models()</a></code>, you’ll get a dialog box from which you can choose your model file. Otherwise, you can provide <code>load_models</code> an absolute path to the file, e.g. <code><a href="../../reference/save_models.html">load_models("C:/Users/user.name/Documents/diabetes/my_models.RDS")</a></code>, or a path relative to your working directory, which again you can find with <code>getwd()</code>, e.g. <code><a href="../../reference/save_models.html">load_models("data/my_models.RDS")</a></code>. If you put the models in the same directory as your R script or project, you can load the models without any file path.</p>
<div class="sourceCode" id="cb21"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb21-1" data-line-number="1">models &lt;-<span class="st"> </span><span class="kw"><a href="../../reference/save_models.html">load_models</a></span>(<span class="st">"my_models.RDS"</span>)</a></code></pre></div>
<p>That will reestablish the <code>models</code> object in your R session. You can confirm this by clicking on the “Environment” tab in R Studio or running <code>ls()</code> to list all objects in your R session.</p>
</div>
<div id="a-regression-example" class="section level1">
<h1 class="hasAnchor">
<a href="#a-regression-example" class="anchor"></a>A Regression Example</h1>
<p>All the examples above have been classification tasks, predicting a yes/no outcome. Here’s an example of a full regression modeling pipeline on a silly problem: predicting individuals’ ages. The code is very similar to classification.</p>
<div class="sourceCode" id="cb22"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb22-1" data-line-number="1">regression_models &lt;-<span class="st"> </span><span class="kw"><a href="../../reference/machine_learn.html">machine_learn</a></span>(pima_diabetes, patient_id, <span class="dt">outcome =</span> age)</a>
<a class="sourceLine" id="cb22-2" data-line-number="2"><span class="co"># &gt; Training new data prep recipe...</span></a>
<a class="sourceLine" id="cb22-3" data-line-number="3"><span class="co"># &gt; Variable(s) ignored in prep_data won't be used to tune models: patient_id</span></a>
<a class="sourceLine" id="cb22-4" data-line-number="4"><span class="co"># &gt; </span></a>
<a class="sourceLine" id="cb22-5" data-line-number="5"><span class="co"># &gt; age looks numeric, so training regression algorithms.</span></a>
<a class="sourceLine" id="cb22-6" data-line-number="6"><span class="co"># &gt; </span></a>
<a class="sourceLine" id="cb22-7" data-line-number="7"><span class="co"># &gt; After data processing, models are being trained on 14 features with 768 observations.</span></a>
<a class="sourceLine" id="cb22-8" data-line-number="8"><span class="co"># &gt; Based on n_folds = 5 and hyperparameter settings, the following number of models will be trained: 50 rf's, 50 xgb's, and 100 glm's</span></a>
<a class="sourceLine" id="cb22-9" data-line-number="9"><span class="co"># &gt; Training with cross validation: Random Forest</span></a>
<a class="sourceLine" id="cb22-10" data-line-number="10"><span class="co"># &gt; Training with cross validation: eXtreme Gradient Boosting</span></a>
<a class="sourceLine" id="cb22-11" data-line-number="11"><span class="co"># &gt; Training with cross validation: glmnet</span></a>
<a class="sourceLine" id="cb22-12" data-line-number="12"><span class="co"># &gt; </span></a>
<a class="sourceLine" id="cb22-13" data-line-number="13"><span class="co"># &gt; *** Models successfully trained. The model object contains the training data minus ignored ID columns. ***</span></a>
<a class="sourceLine" id="cb22-14" data-line-number="14"><span class="co"># &gt; *** If there was PHI in training data, normal PHI protocols apply to the model object. ***</span></a>
<a class="sourceLine" id="cb22-15" data-line-number="15"><span class="kw">summary</span>(regression_models)</a>
<a class="sourceLine" id="cb22-16" data-line-number="16"><span class="co"># &gt; Models trained: 2018-09-01 18:27:53</span></a>
<a class="sourceLine" id="cb22-17" data-line-number="17"><span class="co"># &gt; </span></a>
<a class="sourceLine" id="cb22-18" data-line-number="18"><span class="co"># &gt; Models tuned via 5-fold cross validation over 10 combinations of hyperparameter values.</span></a>
<a class="sourceLine" id="cb22-19" data-line-number="19"><span class="co"># &gt; Best performance: RMSE = 8.9, MAE = 6.3, Rsquared = 0.43</span></a>
<a class="sourceLine" id="cb22-20" data-line-number="20"><span class="co"># &gt; By Random Forest with hyperparameters:</span></a>
<a class="sourceLine" id="cb22-21" data-line-number="21"><span class="co"># &gt;   mtry = 13</span></a>
<a class="sourceLine" id="cb22-22" data-line-number="22"><span class="co"># &gt;   splitrule = extratrees</span></a>
<a class="sourceLine" id="cb22-23" data-line-number="23"><span class="co"># &gt;   min.node.size = 12</span></a>
<a class="sourceLine" id="cb22-24" data-line-number="24"><span class="co"># &gt; </span></a>
<a class="sourceLine" id="cb22-25" data-line-number="25"><span class="co"># &gt; Out-of-fold performance of all trained models:</span></a>
<a class="sourceLine" id="cb22-26" data-line-number="26"><span class="co"># &gt; </span></a>
<a class="sourceLine" id="cb22-27" data-line-number="27"><span class="co"># &gt; $`Random Forest`</span></a>
<a class="sourceLine" id="cb22-28" data-line-number="28"><span class="co"># &gt; # A tibble: 10 x 9</span></a>
<a class="sourceLine" id="cb22-29" data-line-number="29"><span class="co"># &gt;    mtry splitrule min.node.size  RMSE Rsquared   MAE RMSESD RsquaredSD</span></a>
<a class="sourceLine" id="cb22-30" data-line-number="30"><span class="co"># &gt; * &lt;int&gt; &lt;chr&gt;             &lt;int&gt; &lt;dbl&gt;    &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt;      &lt;dbl&gt;</span></a>
<a class="sourceLine" id="cb22-31" data-line-number="31"><span class="co"># &gt; 1    13 extratre…            12  8.91    0.429  6.29  0.952     0.0698</span></a>
<a class="sourceLine" id="cb22-32" data-line-number="32"><span class="co"># &gt; 2     9 extratre…            12  8.92    0.430  6.31  0.939     0.0672</span></a>
<a class="sourceLine" id="cb22-33" data-line-number="33"><span class="co"># &gt; 3     4 variance             11  8.93    0.431  6.40  0.952     0.0678</span></a>
<a class="sourceLine" id="cb22-34" data-line-number="34"><span class="co"># &gt; 4     9 variance             20  9.00    0.418  6.32  1.00      0.0740</span></a>
<a class="sourceLine" id="cb22-35" data-line-number="35"><span class="co"># &gt; 5     3 extratre…             7  9.31    0.422  6.88  0.851     0.0539</span></a>
<a class="sourceLine" id="cb22-36" data-line-number="36"><span class="co"># &gt; # ... with 5 more rows, and 1 more variable: MAESD &lt;dbl&gt;</span></a>
<a class="sourceLine" id="cb22-37" data-line-number="37"><span class="co"># &gt; </span></a>
<a class="sourceLine" id="cb22-38" data-line-number="38"><span class="co"># &gt; $`eXtreme Gradient Boosting`</span></a>
<a class="sourceLine" id="cb22-39" data-line-number="39"><span class="co"># &gt; # A tibble: 10 x 13</span></a>
<a class="sourceLine" id="cb22-40" data-line-number="40"><span class="co"># &gt;      eta max_depth gamma colsample_bytree min_child_weight subsample</span></a>
<a class="sourceLine" id="cb22-41" data-line-number="41"><span class="co"># &gt; *  &lt;dbl&gt;     &lt;int&gt; &lt;dbl&gt;            &lt;dbl&gt;            &lt;dbl&gt;     &lt;dbl&gt;</span></a>
<a class="sourceLine" id="cb22-42" data-line-number="42"><span class="co"># &gt; 1 0.0136         2 8.68             0.597             5.49     0.889</span></a>
<a class="sourceLine" id="cb22-43" data-line-number="43"><span class="co"># &gt; 2 0.0405         6 3.95             0.521             1.73     0.747</span></a>
<a class="sourceLine" id="cb22-44" data-line-number="44"><span class="co"># &gt; 3 0.307          1 8.40             0.531             3.51     0.963</span></a>
<a class="sourceLine" id="cb22-45" data-line-number="45"><span class="co"># &gt; 4 0.136          6 0.209            0.701             1.76     0.905</span></a>
<a class="sourceLine" id="cb22-46" data-line-number="46"><span class="co"># &gt; 5 0.197          7 3.38             0.806             1.85     0.646</span></a>
<a class="sourceLine" id="cb22-47" data-line-number="47"><span class="co"># &gt; # ... with 5 more rows, and 7 more variables: nrounds &lt;int&gt;, RMSE &lt;dbl&gt;,</span></a>
<a class="sourceLine" id="cb22-48" data-line-number="48"><span class="co"># &gt; #   Rsquared &lt;dbl&gt;, MAE &lt;dbl&gt;, RMSESD &lt;dbl&gt;, RsquaredSD &lt;dbl&gt;, MAESD &lt;dbl&gt;</span></a>
<a class="sourceLine" id="cb22-49" data-line-number="49"><span class="co"># &gt; </span></a>
<a class="sourceLine" id="cb22-50" data-line-number="50"><span class="co"># &gt; $glmnet</span></a>
<a class="sourceLine" id="cb22-51" data-line-number="51"><span class="co"># &gt; # A tibble: 20 x 8</span></a>
<a class="sourceLine" id="cb22-52" data-line-number="52"><span class="co"># &gt;   alpha lambda  RMSE Rsquared   MAE RMSESD RsquaredSD MAESD</span></a>
<a class="sourceLine" id="cb22-53" data-line-number="53"><span class="co"># &gt; * &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt;      &lt;dbl&gt; &lt;dbl&gt;</span></a>
<a class="sourceLine" id="cb22-54" data-line-number="54"><span class="co"># &gt; 1     1 0.0318  9.40    0.363  6.76  0.743     0.0520 0.453</span></a>
<a class="sourceLine" id="cb22-55" data-line-number="55"><span class="co"># &gt; 2     1 0.0303  9.40    0.363  6.76  0.743     0.0520 0.453</span></a>
<a class="sourceLine" id="cb22-56" data-line-number="56"><span class="co"># &gt; 3     1 0.0288  9.40    0.363  6.76  0.743     0.0520 0.453</span></a>
<a class="sourceLine" id="cb22-57" data-line-number="57"><span class="co"># &gt; 4     1 0.0795  9.40    0.363  6.75  0.746     0.0532 0.442</span></a>
<a class="sourceLine" id="cb22-58" data-line-number="58"><span class="co"># &gt; 5     1 0.0208  9.40    0.363  6.76  0.742     0.0517 0.455</span></a>
<a class="sourceLine" id="cb22-59" data-line-number="59"><span class="co"># &gt; # ... with 15 more rows</span></a></code></pre></div>
<p>Let’s make a prediction on a hypothetical new patient. Note that the model handles missingness in <code>insulin</code> and a new category level in <code>weight_class</code> without a problem (but warns about it).</p>
<div class="sourceCode" id="cb23"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb23-1" data-line-number="1">new_patient &lt;-<span class="st"> </span><span class="kw">data.frame</span>(</a>
<a class="sourceLine" id="cb23-2" data-line-number="2">  <span class="dt">pregnancies =</span> <span class="dv">0</span>,</a>
<a class="sourceLine" id="cb23-3" data-line-number="3">  <span class="dt">plasma_glucose =</span> <span class="dv">80</span>,</a>
<a class="sourceLine" id="cb23-4" data-line-number="4">  <span class="dt">diastolic_bp =</span> <span class="dv">55</span>,</a>
<a class="sourceLine" id="cb23-5" data-line-number="5">  <span class="dt">skinfold =</span> <span class="dv">24</span>,</a>
<a class="sourceLine" id="cb23-6" data-line-number="6">  <span class="dt">insulin =</span> <span class="ot">NA</span>,</a>
<a class="sourceLine" id="cb23-7" data-line-number="7">  <span class="dt">weight_class =</span> <span class="st">"???"</span>,</a>
<a class="sourceLine" id="cb23-8" data-line-number="8">  <span class="dt">pedigree =</span> <span class="fl">.2</span>,</a>
<a class="sourceLine" id="cb23-9" data-line-number="9">  <span class="dt">diabetes =</span> <span class="st">"N"</span>)</a>
<a class="sourceLine" id="cb23-10" data-line-number="10"><span class="kw">predict</span>(regression_models, new_patient)</a>
<a class="sourceLine" id="cb23-11" data-line-number="11"><span class="co"># &gt; Warning in ready_with_prep(object, newdata, mi): The following variables(s) had the following value(s) in predict that were not observed in training. </span></a>
<a class="sourceLine" id="cb23-12" data-line-number="12"><span class="co"># &gt;     weight_class: ???</span></a>
<a class="sourceLine" id="cb23-13" data-line-number="13"><span class="co"># &gt; Prepping data based on provided recipe</span></a>
<a class="sourceLine" id="cb23-14" data-line-number="14"><span class="co"># &gt; "predicted_age" predicted by Random Forest last trained: 2018-09-01 18:27:53</span></a>
<a class="sourceLine" id="cb23-15" data-line-number="15"><span class="co"># &gt; Performance in training: RMSE = 8.91</span></a>
<a class="sourceLine" id="cb23-16" data-line-number="16"><span class="co"># &gt; # A tibble: 1 x 9</span></a>
<a class="sourceLine" id="cb23-17" data-line-number="17"><span class="co"># &gt;   predicted_age pregnancies plasma_glucose diastolic_bp skinfold insulin</span></a>
<a class="sourceLine" id="cb23-18" data-line-number="18"><span class="co"># &gt; *         &lt;dbl&gt;       &lt;dbl&gt;          &lt;dbl&gt;        &lt;dbl&gt;    &lt;dbl&gt; &lt;lgl&gt;  </span></a>
<a class="sourceLine" id="cb23-19" data-line-number="19"><span class="co"># &gt; 1          24.0           0             80           55       24 NA     </span></a>
<a class="sourceLine" id="cb23-20" data-line-number="20"><span class="co"># &gt; # ... with 3 more variables: weight_class &lt;fct&gt;, pedigree &lt;dbl&gt;,</span></a>
<a class="sourceLine" id="cb23-21" data-line-number="21"><span class="co"># &gt; #   diabetes &lt;fct&gt;</span></a></code></pre></div>
</div>
  </div>

  <div class="col-md-3 hidden-xs hidden-sm" id="sidebar">
        <div id="tocnav">
      <h2 class="hasAnchor">
<a href="#tocnav" class="anchor"></a>Contents</h2>
      <ul class="nav nav-pills nav-stacked">
<li><a href="#easy-machine-learning">Easy Machine Learning</a></li>
      <li><a href="#data-profiling">Data Profiling</a></li>
      <li><a href="#data-preparation">Data Preparation</a></li>
      <li>
<a href="#model-training">Model Training</a><ul class="nav nav-pills nav-stacked">
<li><a href="#faster-model-training">Faster Model Training</a></li>
      </ul>
</li>
      <li>
<a href="#model-interpretation">Model Interpretation</a><ul class="nav nav-pills nav-stacked">
<li><a href="#interpret">Interpret</a></li>
      <li><a href="#variable-importance">Variable Importance</a></li>
      <li><a href="#explore">Explore</a></li>
      </ul>
</li>
      <li><a href="#prediction">Prediction</a></li>
      <li><a href="#saving-moving-and-loading-models">Saving, Moving, and Loading Models</a></li>
      <li><a href="#a-regression-example">A Regression Example</a></li>
      </ul>
</div>
      </div>

</div>


      <footer><div class="copyright">
  <p>Developed by Levi Thatcher, Michael Levy, Mike Mastanduno, Taylor Larsen, Taylor Miller.</p>
</div>

<div class="pkgdown">
  <p>Site built with <a href="http://pkgdown.r-lib.org/">pkgdown</a>.</p>
</div>

      </footer>
</div>

  
<script type="text/javascript" src="https://cdn.jsdelivr.net/npm/docsearch.js@2/dist/cdn/docsearch.min.js"></script><script>
  docsearch({
    
    
    apiKey: 'ac39465bc37cbef616f5de1e646b6037',
    indexName: 'healthcareai',
    inputSelector: 'input#search-input.form-control',
    transformData: function(hits) {
      return hits.map(function (hit) {
        hit.url = updateHitURL(hit);
        return hit;
      });
    }
  });
</script>
</body>
</html>
